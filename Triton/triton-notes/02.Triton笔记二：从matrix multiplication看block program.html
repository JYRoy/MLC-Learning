<!DOCTYPE html><html><head>
      <title>02.Triton笔记二：从matrix multiplication看block program</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/zhangjunyu/.vscode-server/extensions/shd101wyy.markdown-preview-enhanced-0.8.13/crossnote/dependencies/katex/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="triton笔记二">Triton笔记二 </h1>
<ul>
<li><a href="#triton%E7%AC%94%E8%AE%B0%E4%BA%8C">Triton笔记二</a>
<ul>
<li><a href="#motivations">Motivations</a>
<ul>
<li><a href="#pointer-arithmetic">Pointer Arithmetic</a></li>
<li><a href="#l2-cache-optimizations">L2 Cache Optimizations</a></li>
</ul>
</li>
<li><a href="#%E5%AE%9E%E7%8E%B0">实现</a></li>
<li><a href="#compute-kernel">Compute Kernel</a>
<ul>
<li><a href="#%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89">函数定义</a></li>
<li><a href="#program-%E6%A6%82%E5%BF%B5">Program 概念</a></li>
<li><a href="#block-%E6%A6%82%E5%BF%B5">Block 概念</a></li>
<li><a href="#kernel-fusion">Kernel Fusion</a></li>
</ul>
</li>
<li><a href="#%E4%BB%A3%E7%A0%81%E5%92%8C%E6%80%A7%E8%83%BD">代码和性能</a></li>
<li><a href="#references">References</a></li>
</ul>
</li>
</ul>
<h2 id="motivations">Motivations </h2>
<p>传统的情况下，我们开发应用会选择使用厂商提供的计算库中的矩阵乘计算，例如cublas库，但是这种类型的库通常都是不开源的，对于现在更加多样的深度学习场景，我们很难去二次开发它。</p>
<p>相比之下，Triton的优势就非常的明显了，我们可以轻松的使用它来开发一些<strong>fused kernel</strong>，最典型的就是把activation和matrix multiplication结合起来。</p>
<p>对于MM的优化，其实大概的思路都差不多，因为总的计算量一定是不变的，所以能做的事情就是尽可能地使用shared memory，提高<strong>cache hit rate</strong>。</p>
<p>cache hit rate 理解为尽可能的数据复用。小矩阵通常能够被放入cache中。</p>
<p>shared memory(L1 Cache)每次从global memory获取需要的数据时，会先去L2 Cache看是否存在，如果有就不用再去global memory了，有的概率越高，意味着cache hit rate越高。</p>
<p>所以我们希望尽可能的利用SRAM，但是因为它的空间比较小，所以基本原则是：每次往SRAM移动的数据，都要尽可能的被利用，避免来来回回搬迁。因此，更小的分块有利于提高缓存命中率。</p>
<p>除了上述两点，Triton另一个比较有意思的特点是，其操作的粒度大体来说既不是在标量这样细的颗粒度，也不是在Tensor这样相对高层次的颗粒度，而是在<strong>Block或Tile</strong>这种距离AI加速器更近的粒度(注: Block更像是一种逻辑概念，因为 其可以基于Tensor这一数据类型，配合一些属性完成定义)。一言以概，使用Triton开发kernel，Block这个层次的逻辑需要用户来处理，比如输入输出数据的分拆，Block粒度的数据累加等等。</p>
<h3 id="pointer-arithmetic">Pointer Arithmetic </h3>
<p>对于内存中连续存储的2D矩阵x，想要通过指针来访问对应下标中的元素，要借助row和col方向上的stride，公式为：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>X<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> X_ptr <span class="token operator">+</span> i <span class="token operator">*</span> stride_xi <span class="token operator">+</span> j <span class="token operator">*</span> stride_xj
</code></pre><p>因此，如果要访问一个block的元素，采用类似的</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token operator">&amp;</span>A<span class="token punctuation">[</span>m <span class="token punctuation">:</span> m<span class="token operator">+</span>BLOCK_SIZE_M<span class="token punctuation">,</span> k <span class="token punctuation">:</span> k<span class="token operator">+</span>BLOCK_SIZE_K<span class="token punctuation">]</span> <span class="token operator">=</span> a_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>m <span class="token punctuation">:</span> m<span class="token operator">+</span>BLOCK_SIZE_M<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> A<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>k <span class="token punctuation">:</span> k<span class="token operator">+</span>BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">*</span>A<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>B<span class="token punctuation">[</span>k <span class="token punctuation">:</span> k<span class="token operator">+</span>BLOCK_SIZE_K<span class="token punctuation">,</span> n <span class="token punctuation">:</span> n<span class="token operator">+</span>BLOCK_SIZE_N<span class="token punctuation">]</span> <span class="token operator">=</span> b_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>k <span class="token punctuation">:</span> k<span class="token operator">+</span>BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>n <span class="token punctuation">:</span> n<span class="token operator">+</span>BLOCK_SIZE_N<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">*</span>B<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><p><code>[:, None]</code>是python支持的用法，用于在保证原始数据不变的情况下追加新维度。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> NP
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a <span class="token operator">=</span> NP<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> NP<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span> <span class="token number">8</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>b<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">10</span> <span class="token operator">+</span> b<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">11</span> <span class="token number">12</span> <span class="token number">13</span> <span class="token number">14</span> <span class="token number">15</span> <span class="token number">16</span> <span class="token number">17</span> <span class="token number">18</span> <span class="token number">19</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">21</span> <span class="token number">22</span> <span class="token number">23</span> <span class="token number">24</span> <span class="token number">25</span> <span class="token number">26</span> <span class="token number">27</span> <span class="token number">28</span> <span class="token number">29</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">31</span> <span class="token number">32</span> <span class="token number">33</span> <span class="token number">34</span> <span class="token number">35</span> <span class="token number">36</span> <span class="token number">37</span> <span class="token number">38</span> <span class="token number">39</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">41</span> <span class="token number">42</span> <span class="token number">43</span> <span class="token number">44</span> <span class="token number">45</span> <span class="token number">46</span> <span class="token number">47</span> <span class="token number">48</span> <span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre><h3 id="l2-cache-optimizations">L2 Cache Optimizations </h3>
<p>每一个program可以计算得到C中的一个[BLOCK_SIZE_M, BLOCK_SIZE_N]的block。</p>
<p>为了保证L2 Cache的命中率，这些block的顺序非常重要。</p>
<p>如果采用传统的行主序的形式（也就是从左到右，从上到下，一个一个block的按顺序计算），triton实现如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token decorator annotation punctuation">@triton<span class="token punctuation">.</span>autotune</span><span class="token punctuation">(</span>
    configs<span class="token operator">=</span>get_autotune_config<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"M"</span><span class="token punctuation">,</span> <span class="token string">"N"</span><span class="token punctuation">,</span> <span class="token string">"K"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token decorator annotation punctuation">@triton<span class="token punctuation">.</span>jit</span>
<span class="token keyword keyword-def">def</span> <span class="token function">naive_matmul_kernel</span><span class="token punctuation">(</span>
    <span class="token comment"># Pointers to matrices</span>
    A<span class="token punctuation">,</span>
    B<span class="token punctuation">,</span>
    C<span class="token punctuation">,</span>
    <span class="token comment"># Matrix dimensions</span>
    M<span class="token punctuation">,</span>
    N<span class="token punctuation">,</span>
    K<span class="token punctuation">,</span>
    <span class="token comment"># The stride variables represent how much to increase the ptr by when moving by 1</span>
    <span class="token comment"># element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`</span>
    <span class="token comment"># by to get the element one row down (A has M rows).</span>
    stride_am<span class="token punctuation">,</span>
    stride_ak<span class="token punctuation">,</span>  <span class="token comment">#</span>
    stride_bk<span class="token punctuation">,</span>
    stride_bn<span class="token punctuation">,</span>  <span class="token comment">#</span>
    stride_cm<span class="token punctuation">,</span>
    stride_cn<span class="token punctuation">,</span>
    <span class="token comment"># Meta-parameters</span>
    BLOCK_SIZE_M<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>
    BLOCK_SIZE_N<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>
    BLOCK_SIZE_K<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>  <span class="token comment">#</span>
    GROUP_SIZE_M<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>  <span class="token comment">#</span>
    ACTIVATION<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>  <span class="token comment">#</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    mid <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    nid <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># Starting row + BLOCK_SIZE_M more rows</span>
    a_rows <span class="token operator">=</span> mid <span class="token operator">*</span> BLOCK_SIZE_M <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
    <span class="token comment"># Starting col + BLOCK_SIZE_N more columns</span>
    b_cols <span class="token operator">=</span> nid <span class="token operator">*</span> BLOCK_SIZE_N <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>

    a_ptrs <span class="token operator">=</span> a_ptr <span class="token operator">+</span> a_rows<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> K <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    b_ptrs <span class="token operator">=</span> b_ptr <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> N <span class="token operator">+</span> b_cols<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

    c <span class="token operator">=</span> tl<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>BLOCK_SIZE_M<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tl<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> k <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>K<span class="token operator">//</span>BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">:</span>
        a <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>a_ptrs<span class="token punctuation">)</span>
        b <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>b_ptrs<span class="token punctuation">)</span>
        c <span class="token operator">+=</span> tl<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
        a_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K
        b_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> N

    c <span class="token operator">=</span> c<span class="token punctuation">.</span>to<span class="token punctuation">(</span>tl<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>

    <span class="token comment"># C's block's offsets</span>
    c_ptrs <span class="token operator">=</span> a_rows<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> N <span class="token operator">+</span> b_cols<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    tl<span class="token punctuation">.</span>store<span class="token punctuation">(</span>c_ptr<span class="token operator">+</span> c_ptrs<span class="token punctuation">,</span> c<span class="token punctuation">)</span>
</code></pre><p>一种可能的解决方案是按照促进数据重用的顺序启动block。triton可以通过在切换到下一列之前的super-grouping block来完成：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Program ID</span>
pid <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># Number of program ids along the M axis</span>
num_pid_m <span class="token operator">=</span> tl<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>M<span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
<span class="token comment"># Number of programs ids along the N axis</span>
num_pid_n <span class="token operator">=</span> tl<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>N<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>
<span class="token comment"># Number of programs in group</span>
num_pid_in_group <span class="token operator">=</span> GROUP_SIZE_M <span class="token operator">*</span> num_pid_n
<span class="token comment"># Id of the group this program is in</span>
group_id <span class="token operator">=</span> pid <span class="token operator">//</span> num_pid_in_group
<span class="token comment"># Row-id of the first program in the group</span>
first_pid_m <span class="token operator">=</span> group_id <span class="token operator">*</span> GROUP_SIZE_M
<span class="token comment"># If `num_pid_m` isn't divisible by `GROUP_SIZE_M`, the last group is smaller</span>
group_size_m <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_pid_m <span class="token operator">-</span> first_pid_m<span class="token punctuation">,</span> GROUP_SIZE_M<span class="token punctuation">)</span>
<span class="token comment"># *Within groups*, programs are ordered in a column-major order</span>
<span class="token comment"># Row-id of the program in the *launch grid*</span>
pid_m <span class="token operator">=</span> first_pid_m <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>pid <span class="token operator">%</span> num_pid_in_group<span class="token punctuation">)</span> <span class="token operator">%</span> group_size_m<span class="token punctuation">)</span>
<span class="token comment"># Col-id of the program in the *launch grid*</span>
pid_n <span class="token operator">=</span> <span class="token punctuation">(</span>pid <span class="token operator">%</span> num_pid_in_group<span class="token punctuation">)</span> <span class="token operator">//</span> group_size_m
</code></pre><p>这样看代码还是很抽象，但是可视化来看，就非常的清楚了，下面这种grouped ordering的方式，可以尽可能的提高cache hit rate，如果对于计算相同量级的C block，需要加载的block更少，因此对于默认将数据加载到L2 Cache区域的GPU来说，这种方式更加的友好</p>
<ol>
<li>row-major ordering：读入90个block，写9个block</li>
<li>grouped ordering：读入54个block，写9个block</li>
</ol>
<p><img src="../.images/grouped_vs_row_major_ordering.png" alt="grouped_vs_row_major_ordering.png"></p>
<p>实现上，我们采用对A的黄色区域行方向滚动，B的黄色区域列方向滚动，在C的黄色区域上不断的累加。</p>
<p>滚动计算过程中的更小的区域被称为tile，它会被加载到shared memory中（片上的）。也就是说A、B tile每次窗口滑动都是重新load到shared memory的，计算时再被加载到register上，而C tile一直在register中。如果所有的黄色区域，都能够在L2 Cache上存储下来，shared memory再次加载数据时，就不用从片外内存上去搬了，而是直接L2 Cache中就可以命中。</p>
<p>也就是说，如果我们想提高cache hit rate实现高效的矩阵乘，那么在分块计算过程中，C的块将会按图中index顺序，逐个被计算出来。</p>
<h2 id="实现">实现 </h2>
<h2 id="compute-kernel">Compute Kernel </h2>
<p>首先通过伪代码来看Triton中的(M, K) * (K, N) = (M, N)的矩阵乘的blocked算法。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># M 维度上每次取BLOCK_SIZE_M大小的数据，m为当前block在M维度上的起始位置</span>
<span class="token keyword keyword-for">for</span> m <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> M<span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># N 维度上每次取BLOCK_SIZE_N大小的数据，n为当前block在N维度上的起始位置</span>
    <span class="token keyword keyword-for">for</span> n <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> N<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># acc用于存储输出矩阵的一个块，因此大小是(BLOCK_SIZE_M, BLOCK_SIZE_N)</span>
        acc <span class="token operator">=</span> zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>BLOCK_SIZE_M<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>
        <span class="token comment"># 固定了M和N维度后，在K维度上滑动，每次的窗口大小是BLOCK_SIZE_K</span>
        <span class="token keyword keyword-for">for</span> k <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> K<span class="token punctuation">,</span> BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 读取a block</span>
            a <span class="token operator">=</span> A<span class="token punctuation">[</span>m <span class="token punctuation">:</span> m<span class="token operator">+</span>BLOCK_SIZE_M<span class="token punctuation">,</span> k <span class="token punctuation">:</span> k<span class="token operator">+</span>BLOCK_SIZE_K<span class="token punctuation">]</span>
            <span class="token comment"># 读取b block</span>
            b <span class="token operator">=</span> B<span class="token punctuation">[</span>k <span class="token punctuation">:</span> k<span class="token operator">+</span>BLOCK_SIZE_K<span class="token punctuation">,</span> n <span class="token punctuation">:</span> n<span class="token operator">+</span>BLOCK_SIZE_N<span class="token punctuation">]</span>
            <span class="token comment"># a block和b block进行矩阵乘，获取到输出block的一部分</span>
            acc <span class="token operator">+=</span> dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
        <span class="token comment"># K维度上滑动完，获取到完成的输出block</span>
        C<span class="token punctuation">[</span>m <span class="token punctuation">:</span> m<span class="token operator">+</span>BLOCK_SIZE_M<span class="token punctuation">,</span> n <span class="token punctuation">:</span> n<span class="token operator">+</span>BLOCK_SIZE_N<span class="token punctuation">]</span> <span class="token operator">=</span> acc
</code></pre><p>从代码中可以看到，A和B都是分块的来取数据的，计算得到的结果也是C中的一块，当前M、N方向上的BLOCK_SIZE大小的数据，可以在K方向上不断滑动，相当于每次计算C的一块的一部分数据，滑动的过程就是累加的过程。</p>
<h3 id="函数定义">函数定义 </h3>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token decorator annotation punctuation">@triton<span class="token punctuation">.</span>jit</span>
<span class="token keyword keyword-def">def</span> <span class="token function">matmul_kernel</span><span class="token punctuation">(</span>
    <span class="token comment"># Pointers to matrices</span>
    a_ptr<span class="token punctuation">,</span>
    b_ptr<span class="token punctuation">,</span>
    c_ptr<span class="token punctuation">,</span>
    <span class="token comment"># Matrix dimensions</span>
    M<span class="token punctuation">,</span>
    N<span class="token punctuation">,</span>
    K<span class="token punctuation">,</span>
    <span class="token comment"># The stride variables represent how much to increase the ptr by when moving by 1</span>
    <span class="token comment"># element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`</span>
    <span class="token comment"># by to get the element one row down (A has M rows).</span>
    stride_am<span class="token punctuation">,</span>
    stride_ak<span class="token punctuation">,</span>  <span class="token comment">#</span>
    stride_bk<span class="token punctuation">,</span>
    stride_bn<span class="token punctuation">,</span>  <span class="token comment">#</span>
    stride_cm<span class="token punctuation">,</span>
    stride_cn<span class="token punctuation">,</span>
    <span class="token comment"># Meta-parameters</span>
    BLOCK_SIZE_M<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>
    BLOCK_SIZE_N<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>
    BLOCK_SIZE_K<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>  <span class="token comment">#</span>
    GROUP_SIZE_M<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>  <span class="token comment">#</span>
    ACTIVATION<span class="token punctuation">:</span> tl<span class="token punctuation">.</span>constexpr<span class="token punctuation">,</span>  <span class="token comment">#</span>
<span class="token punctuation">)</span>
</code></pre><ol>
<li><code>a_ptr</code>、<code>b_ptr</code>、<code>c_ptr</code>：tensor的指针，第一个元素的地址；</li>
<li>strides：和我们在torch中看到的stride是同一个概念，strid0对应0维+1需要的stride，stride1对应1维+1需要的stride，如果shape是一个(3,4)的tensor，那么它的stride是(4,1)；</li>
<li>Meta-parameters：剩下的tl.constexpr都是超参数l，在triton中超参数通过triton.Config和triton.autotune来设置；</li>
</ol>
<h3 id="program-概念">Program 概念 </h3>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>pid <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><p>这是在vector add用例中就已经看过的内容。在kernel中，写成只处理C的一部分输出的形式，但是执行完kernel后可以得到完成的C的原因，就是program在发挥它的作用。</p>
<p>program其实可以理解成循环，program_id理解成循环的index。</p>
<p>axis理解为嵌套的循环中有第几层循环，axis=0意味着只有一层循环，axis=1意味着有两层嵌套的循环，以此类推。</p>
<p>这个program在什么时候决定它到底有几层呢？其实不是在axis这里，这里可以理解为取出index。真正的设置循环的层数的地方在host代码中调用kernel的位置。</p>
<p>也就是这里的grid，它被定义为了一个lambda函数，它的值和输入x的M、N维度以及BLOCK_SIZE有关系，是一个一维值。能够和kernel内的axis=0对应上，都是一层的。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>grid <span class="token operator">=</span> <span class="token keyword keyword-lambda">lambda</span> META<span class="token punctuation">:</span> <span class="token punctuation">(</span>
    triton<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>M<span class="token punctuation">,</span> META<span class="token punctuation">[</span><span class="token string">"BLOCK_SIZE_M"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> triton<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>N<span class="token punctuation">,</span> META<span class="token punctuation">[</span><span class="token string">"BLOCK_SIZE_N"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
matmul_kernel<span class="token punctuation">[</span>grid<span class="token punctuation">]</span><span class="token punctuation">(</span>
    a<span class="token punctuation">,</span>
    b<span class="token punctuation">,</span>
    c<span class="token punctuation">,</span>  <span class="token comment">#</span>
    M<span class="token punctuation">,</span>
    N<span class="token punctuation">,</span>
    K<span class="token punctuation">,</span>  <span class="token comment">#</span>
    a<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    a<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">#</span>
    b<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    b<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">#</span>
    c<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    c<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">#</span>
    ACTIVATION<span class="token operator">=</span>activation<span class="token punctuation">,</span>  <span class="token comment">#</span>
<span class="token punctuation">)</span>
</code></pre><h3 id="block-概念">Block 概念 </h3>
<p>Block的概念，就是建立在program基础之上。</p>
<p>前面说了program理解为循环，每一个index对应了输出C矩阵中的一部分，这一部分就是我们说的block，block的大小是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>B</mi><mi>L</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>M</mi></mrow><mo>×</mo><mrow><mi>B</mi><mi>L</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>N</mi></mrow></mrow><annotation encoding="application/x-tex">{BLOCK\_SIZE\_M} \times {BLOCK\_SIZE\_N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.07153em;">OC</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">ZE</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.07153em;">OC</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">ZE</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span>，则循环的次数就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>M</mi><mrow><mi>B</mi><mi>L</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>M</mi></mrow></mfrac><mo>×</mo><mfrac><mi>N</mi><mrow><mi>B</mi><mi>L</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{M}{BLOCK\_SIZE\_M} \times \frac{N}{BLOCK\_SIZE\_N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4343em;vertical-align:-0.562em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">OC</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">ZE</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.562em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4343em;vertical-align:-0.562em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">OC</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">ZE</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.562em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</p>
<p>也就是说，完成<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>×</mo><mi>B</mi><mo>=</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A\times B=C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>，A的大小是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">M \times K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>，B的大小是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">K \times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>，的运算，我们需要计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>M</mi><mrow><mi>B</mi><mi>L</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>M</mi></mrow></mfrac><mo>×</mo><mfrac><mi>N</mi><mrow><mi>B</mi><mi>L</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{M}{BLOCK\_SIZE\_M} \times \frac{N}{BLOCK\_SIZE\_N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4343em;vertical-align:-0.562em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">OC</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">ZE</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.562em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4343em;vertical-align:-0.562em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">OC</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">ZE</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.562em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>个block的内容。对于上面的图，grid=81。</p>
<p>所以，从block的角度，就是上面的super grouped ordering：先计算9个blocks，组合成一个大的super block，在进行下一个super block。</p>
<p>它的好处就是：</p>
<ol>
<li>同样都是计算9个block，读入的block更少</li>
<li>cache hit rate更高</li>
</ol>
<p>对于输出C，它需要计算0到80的81个block。当program在axis=0维度上递增时，我们期望形成一下的代码逻辑： (pid_m, pid_n) 是黄色小块的坐标,</p>
<pre data-role="codeBlock" data-info="c++" class="language-cpp c++"><code><span class="token keyword keyword-for">for</span> pid in <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">81</span><span class="token punctuation">)</span><span class="token operator">:</span>
    pid <span class="token operator">--</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>pid_m<span class="token punctuation">,</span> pid_n<span class="token punctuation">)</span>
</code></pre><p>对应到triton中的实现，我们要做的就是把pid转换为pid_m和pid_n，让pid_m按照(0,1,2,0,1,2,…,0,1,2)的序列变化，让pid_n按照(0,0,0,1,1,1,2,2,2,…,8,8,8)的序列变化，这样(pid_m,pid_n)组合可以生成(0,0),(1,0),(2,0),(0,1),(1,1),(1,2),…,(0,8),(1,8),(2,8)的序列。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Program ID</span>
pid <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># Number of program ids along the M axis</span>
num_pid_m <span class="token operator">=</span> tl<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>M<span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
<span class="token comment"># Number of programs ids along the N axis</span>
num_pid_n <span class="token operator">=</span> tl<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>N<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>
<span class="token comment"># Number of programs in group</span>
num_pid_in_group <span class="token operator">=</span> GROUP_SIZE_M <span class="token operator">*</span> num_pid_n
<span class="token comment"># Id of the group this program is in</span>
group_id <span class="token operator">=</span> pid <span class="token operator">//</span> num_pid_in_group
<span class="token comment"># Row-id of the first program in the group</span>
first_pid_m <span class="token operator">=</span> group_id <span class="token operator">*</span> GROUP_SIZE_M
<span class="token comment"># If `num_pid_m` isn't divisible by `GROUP_SIZE_M`, the last group is smaller</span>
group_size_m <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_pid_m <span class="token operator">-</span> first_pid_m<span class="token punctuation">,</span> GROUP_SIZE_M<span class="token punctuation">)</span>
<span class="token comment"># *Within groups*, programs are ordered in a column-major order</span>
<span class="token comment"># Row-id of the program in the *launch grid*</span>
pid_m <span class="token operator">=</span> first_pid_m <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>pid <span class="token operator">%</span> num_pid_in_group<span class="token punctuation">)</span> <span class="token operator">%</span> group_size_m<span class="token punctuation">)</span>
<span class="token comment"># Col-id of the program in the *launch grid*</span>
pid_n <span class="token operator">=</span> <span class="token punctuation">(</span>pid <span class="token operator">%</span> num_pid_in_group<span class="token punctuation">)</span> <span class="token operator">//</span> group_size_m
</code></pre><ul>
<li>num_pid_m和num_pid_n：C矩阵长宽两个维度各组有多少的block（有多少个pid）</li>
<li>num_pid_in_group：下图中红框部分的block数，高GROUP_SIZE_M，宽num_pid_n。对应一个红框内的block，它们会依次计算</li>
<li>group_id：红色框的id，当前pid在第几个框里</li>
<li>first_pid_m：当前group在m维度上的第一个pid是多少</li>
<li>group_size_m：因为最后一个group可能不满，所以需要获取当前pid的实际group size m</li>
<li>pid_m和pid_n：是我们最后想要的值，当前pid（当前循环）在第几个block上
<ul>
<li>pid_m一定小于first_pid_m + group_size_m</li>
</ul>
</li>
</ul>
<p><img src="../.images/grouped%20ordering%20num_pid_in_group.png" alt="grouped ordering num_pid_in_group.png"></p>
<p>前面还是从高层的角度看block和super group。下面深入到一个block中，也就是triton kernel实现的角度。</p>
<p><img src="../.images/one%20block%20computation.png" alt="one block computation.png"></p>
<p>A中第一行的9个block和B中第一列的9个block逐个相乘，逐个放入accumulator累加器中，9个block计算完，accumulator累加器中的值也就是C中的第一个block。</p>
<p>所以，对于每一个pid，需要构造一个循环来读取A和B上的9个block。</p>
<p>首先，定位到开始的一个block</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># ----------------------------------------------------------</span>
<span class="token comment"># Create pointers for the first blocks of A and B.</span>
<span class="token comment"># We will advance this pointer as we move in the K direction</span>
<span class="token comment"># and accumulate</span>
<span class="token comment"># `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers</span>
<span class="token comment"># `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers</span>
<span class="token comment"># See above `Pointer Arithmetics` section for details</span>
offs_am <span class="token operator">=</span> <span class="token punctuation">(</span>pid_m <span class="token operator">*</span> BLOCK_SIZE_M <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">%</span> M
offs_bn <span class="token operator">=</span> <span class="token punctuation">(</span>pid_n <span class="token operator">*</span> BLOCK_SIZE_N <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">%</span> N
offs_k <span class="token operator">=</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_K<span class="token punctuation">)</span>
a_ptrs <span class="token operator">=</span> a_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>offs_am<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_am <span class="token operator">+</span> offs_k<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_ak<span class="token punctuation">)</span>
b_ptrs <span class="token operator">=</span> b_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>offs_k<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_bk <span class="token operator">+</span> offs_bn<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_bn<span class="token punctuation">)</span>
</code></pre><p>以第一个block为例：</p>
<ul>
<li>offs_am：A矩阵9个block中的第一个block中每个元素在整个A矩阵中的行坐标</li>
<li>offs_bn：B矩阵9个block中的第一个block中每个元素在整个B矩阵中的列坐标</li>
<li>offs_k：A矩阵的列坐标，B矩阵的行坐标</li>
<li>a_ptr：A矩阵的第一个元素的地址</li>
<li>b_ptr: B矩阵的第一个元素的地址</li>
</ul>
<p>有了行列坐标之后，和stride相乘，即可以得到第一个block中每个元素的坐标a_ptr和b_ptrs</p>
<p>有了具体的坐标之后，进行乘加运算，这个运算过程其实就是一个block一个block的计算它们的矩阵乘法</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># -----------------------------------------------------------</span>
<span class="token comment"># Iterate to compute a block of the C matrix.</span>
<span class="token comment"># We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block</span>
<span class="token comment"># of fp32 values for higher accuracy.</span>
<span class="token comment"># `accumulator` will be converted back to fp16 after the loop.</span>
accumulator <span class="token operator">=</span> tl<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>BLOCK_SIZE_M<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tl<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> k <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> tl<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>K<span class="token punctuation">,</span> BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Load the next block of A and B, generate a mask by checking the K dimension.</span>
    <span class="token comment"># If it is out of bounds, set it to 0.</span>
    a <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>a_ptrs<span class="token punctuation">,</span> mask<span class="token operator">=</span>offs_k<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> K <span class="token operator">-</span> k <span class="token operator">*</span> BLOCK_SIZE_K<span class="token punctuation">,</span> other<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>b_ptrs<span class="token punctuation">,</span> mask<span class="token operator">=</span>offs_k<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> K <span class="token operator">-</span> k <span class="token operator">*</span> BLOCK_SIZE_K<span class="token punctuation">,</span> other<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token comment"># We accumulate along the K dimension.</span>
    accumulator <span class="token operator">+=</span> tl<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
    <span class="token comment"># Advance the ptrs to the next K block.</span>
    a_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> stride_ak
    b_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> stride_bk
</code></pre><p>mask的作用是当K不能被BLOCK_SIZE_K整除时，到每一行最后一个block时，实际大小不足BLOCK_SIZE_K，需要使用mask遮蔽掉</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>accumulator <span class="token operator">+=</span> tl<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
</code></pre><p>计算了一个block的值之后移动到下一个block的元素，因为都是在k方向移动，所以只要考虑k方向上的偏移就可以了，对于本例子，stride_ak是1，stride_bk是9，所以a的每个指针移动BLOCK_SIZE_K的位置，b的每个指针移动BLOCK_SIZE_K*9的位置。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>a_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> stride_ak
b_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> stride_bk
</code></pre><p>在k方向上移动完，也就得到了C中的第一个block，写回到DRAM中，即完成了第一个block的全部操作</p>
<p>和load时的思路一致，先找到偏移，<code>pid_m * BLOCK_SIZE_M</code>和<code>pid_n * BLOCK_SIZE_N</code>获取到m、n的起始坐标，再分别加上对应方向的偏移</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>offs_cm <span class="token operator">=</span> pid_m <span class="token operator">*</span> BLOCK_SIZE_M <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
offs_cn <span class="token operator">=</span> pid_n <span class="token operator">*</span> BLOCK_SIZE_N <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>
</code></pre><p>有了偏移之后，偏移和stride获取到实际的坐标，将c（也就是accumulator）写入到c_ptrs中。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># -----------------------------------------------------------</span>
<span class="token comment"># Write back the block of the output matrix C with masks.</span>
offs_cm <span class="token operator">=</span> pid_m <span class="token operator">*</span> BLOCK_SIZE_M <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
offs_cn <span class="token operator">=</span> pid_n <span class="token operator">*</span> BLOCK_SIZE_N <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>
c_ptrs <span class="token operator">=</span> c_ptr <span class="token operator">+</span> stride_cm <span class="token operator">*</span> offs_cm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">+</span> stride_cn <span class="token operator">*</span> offs_cn<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
c_mask <span class="token operator">=</span> <span class="token punctuation">(</span>offs_cm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> M<span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>offs_cn<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
tl<span class="token punctuation">.</span>store<span class="token punctuation">(</span>c_ptrs<span class="token punctuation">,</span> c<span class="token punctuation">,</span> mask<span class="token operator">=</span>c_mask<span class="token punctuation">)</span>
</code></pre><p>在上述的program基础上，叠加上program的并行化，81个block经过81个program计算后得到了完整的C矩阵。</p>
<h3 id="kernel-fusion">Kernel Fusion </h3>
<p>我们一开始提到了，除了cache hit rate和block program这两个特点，triton的开发属性可以带来很好的算子融合特性，依旧以上面的matrix multiplication为例子，我们可以在完成一个block的计算后，直接使用elmentwised算子，例如leak_rule，这样经过triton编译之后，它们实际上是一个cuda kernel。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>accumulator <span class="token operator">=</span> tl<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>BLOCK_SIZE_M<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tl<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> k <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> tl<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>K<span class="token punctuation">,</span> BLOCK_SIZE_K<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Load the next block of A and B, generate a mask by checking the K dimension.</span>
    <span class="token comment"># If it is out of bounds, set it to 0.</span>
    a <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>a_ptrs<span class="token punctuation">,</span> mask<span class="token operator">=</span>offs_k<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> K <span class="token operator">-</span> k <span class="token operator">*</span> BLOCK_SIZE_K<span class="token punctuation">,</span> other<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>b_ptrs<span class="token punctuation">,</span> mask<span class="token operator">=</span>offs_k<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> K <span class="token operator">-</span> k <span class="token operator">*</span> BLOCK_SIZE_K<span class="token punctuation">,</span> other<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token comment"># We accumulate along the K dimension.</span>
    accumulator <span class="token operator">=</span> tl<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> accumulator<span class="token punctuation">)</span>
    <span class="token comment"># Advance the ptrs to the next K block.</span>
    a_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> stride_ak
    b_ptrs <span class="token operator">+=</span> BLOCK_SIZE_K <span class="token operator">*</span> stride_bk
<span class="token comment"># You can fuse arbitrary activation functions here</span>
<span class="token comment"># while the accumulator is still in FP32!</span>
<span class="token keyword keyword-if">if</span> ACTIVATION <span class="token operator">==</span> <span class="token string">"leaky_relu"</span><span class="token punctuation">:</span>
    accumulator <span class="token operator">=</span> leaky_relu<span class="token punctuation">(</span>accumulator<span class="token punctuation">)</span>
c <span class="token operator">=</span> accumulator<span class="token punctuation">.</span>to<span class="token punctuation">(</span>tl<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
</code></pre><p>而这个leaky_rule操作可以是自己实现的</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># We can fuse `leaky_relu` by providing it as an `ACTIVATION` meta-parameter in `_matmul`.</span>
<span class="token decorator annotation punctuation">@triton<span class="token punctuation">.</span>jit</span>
<span class="token keyword keyword-def">def</span> <span class="token function">leaky_relu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">1</span>
    <span class="token keyword keyword-return">return</span> tl<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token number">0.01</span> <span class="token operator">*</span> x<span class="token punctuation">)</span>
</code></pre><h2 id="代码和性能">代码和性能 </h2>
<p>代码：<a href="../triton-examples/02.matrix-multiplication/matrix_multiplication.py">…/triton-examples/02.matrix-multiplication/matrix_multiplication.py</a></p>
<p>性能对比：</p>
<p><img src="../triton-examples/02.matrix-multiplication/matmul-performance-fp16.png" alt="matmul-performance-fp16.png"></p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>M,N,K,cuBLAS,Triton,Naive Triton
256.000000,256.000000,256.000000,2.340571,4.096000,3.640889
512.000000,512.000000,512.000000,21.845333,23.831273,20.164923
768.000000,768.000000,768.000000,44.236801,49.151998,49.151998
1024.000000,1024.000000,1024.000000,55.188213,59.918627,61.680940
1280.000000,1280.000000,1280.000000,65.015874,89.043476,91.022221
1536.000000,1536.000000,1536.000000,85.275760,91.920627,91.920627
1792.000000,1792.000000,1792.000000,93.661869,101.256071,104.068741
2048.000000,2048.000000,2048.000000,99.273464,96.420781,96.978131
2304.000000,2304.000000,2304.000000,100.369213,112.678642,115.960545
2560.000000,2560.000000,2560.000000,115.380278,107.789478,109.959732
2816.000000,2816.000000,2816.000000,99.803677,103.351201,105.603409
3072.000000,3072.000000,3072.000000,102.392589,101.840118,105.837578
3328.000000,3328.000000,3328.000000,100.546506,103.733858,106.338698
3584.000000,3584.000000,3584.000000,100.858547,115.054882,114.834469
3840.000000,3840.000000,3840.000000,114.247936,105.426125,105.325718
4096.000000,4096.000000,4096.000000,115.505790,107.460154,107.978861
4352.000000,4352.000000,4352.000000,101.060378,107.254618,105.152960
4608.000000,4608.000000,4608.000000,99.949255,109.766213,109.264134
4864.000000,4864.000000,4864.000000,89.615515,111.375477,108.630121
5120.000000,5120.000000,5120.000000,99.598784,113.286088,108.234515
5376.000000,5376.000000,5376.000000,87.935222,108.690702,108.225555
5632.000000,5632.000000,5632.000000,99.746614,105.062835,104.013611
5888.000000,5888.000000,5888.000000,99.746876,109.304527,109.110090
6144.000000,6144.000000,6144.000000,100.373326,108.201325,107.956352
6400.000000,6400.000000,6400.000000,99.863465,106.711135,102.523031
6656.000000,6656.000000,6656.000000,99.883863,106.368156,99.745471
6912.000000,6912.000000,6912.000000,97.604804,107.800865,97.619580
7168.000000,7168.000000,7168.000000,97.687666,109.054449,99.643047
7424.000000,7424.000000,7424.000000,96.460924,107.185992,102.386616
7680.000000,7680.000000,7680.000000,95.112453,107.750093,96.824732
7936.000000,7936.000000,7936.000000,93.995615,109.702922,93.963949
8192.000000,8192.000000,8192.000000,94.295410,110.524118,102.671813
8448.000000,8448.000000,8448.000000,92.049060,110.105993,92.229291
8704.000000,8704.000000,8704.000000,112.452064,108.794851,93.717553
8960.000000,8960.000000,8960.000000,112.791267,111.795015,98.515393
9216.000000,9216.000000,9216.000000,107.512221,110.856635,95.512689
9472.000000,9472.000000,9472.000000,116.813108,110.472728,98.143181
9728.000000,9728.000000,9728.000000,116.438656,109.697134,96.924465
9984.000000,9984.000000,9984.000000,116.379175,109.910376,97.972025
10240.000000,10240.000000,10240.000000,116.172830,108.279222,97.789841
10496.000000,10496.000000,10496.000000,116.265713,108.231064,95.695053
10752.000000,10752.000000,10752.000000,112.969547,109.833991,96.204306
11008.000000,11008.000000,11008.000000,114.204287,108.964445,94.527971
11264.000000,11264.000000,11264.000000,113.615647,110.271773,94.700910
11520.000000,11520.000000,11520.000000,114.025429,110.510141,93.379112
11776.000000,11776.000000,11776.000000,116.167905,110.950919,89.894621
12032.000000,12032.000000,12032.000000,113.793089,111.382664,88.807235
12288.000000,12288.000000,12288.000000,116.287864,110.711937,93.315967
12544.000000,12544.000000,12544.000000,113.494433,110.672847,93.099781
12800.000000,12800.000000,12800.000000,115.242306,109.799091,94.434450
13056.000000,13056.000000,13056.000000,112.344164,111.412629,94.128390
13312.000000,13312.000000,13312.000000,114.249220,111.171399,94.963583
13568.000000,13568.000000,13568.000000,114.157389,109.247703,93.259442
13824.000000,13824.000000,13824.000000,112.165477,110.870028,93.143552
14080.000000,14080.000000,14080.000000,112.551638,110.830983,95.425881
14336.000000,14336.000000,14336.000000,112.910279,111.776410,94.814643
14592.000000,14592.000000,14592.000000,110.234408,110.964093,94.608897
14848.000000,14848.000000,14848.000000,116.604597,109.653036,95.821921
15104.000000,15104.000000,15104.000000,110.693936,109.816084,90.657367
15360.000000,15360.000000,15360.000000,111.217602,110.058903,91.795447
15616.000000,15616.000000,15616.000000,111.818416,109.477957,94.051839
15872.000000,15872.000000,15872.000000,110.740520,111.281764,95.416230
16128.000000,16128.000000,16128.000000,109.000130,110.361110,93.268452
16384.000000,16384.000000,16384.000000,111.966195,103.706851,93.865730
16640.000000,16640.000000,16640.000000,109.290999,111.414039,94.658628
16896.000000,16896.000000,16896.000000,108.971195,108.576835,94.927183
17152.000000,17152.000000,17152.000000,108.251162,110.286270,92.872104
17408.000000,17408.000000,17408.000000,109.052791,109.977028,91.796294
17664.000000,17664.000000,17664.000000,106.755491,110.588595,93.763246
17920.000000,17920.000000,17920.000000,109.040161,111.455783,95.975683
18176.000000,18176.000000,18176.000000,107.202195,106.550631,95.816437
18432.000000,18432.000000,18432.000000,104.899866,109.912204,95.475403
18688.000000,18688.000000,18688.000000,105.899290,110.767181,95.559905
18944.000000,18944.000000,18944.000000,106.967252,110.952738,95.109157

</code></pre><h2 id="references">References </h2>
<ul>
<li><a href="https://triton-lang.org/main/getting-started/tutorials/03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py">Triton tutorial matrix multiplication</a> 必看</li>
<li><a href="https://www.zhihu.com/question/622685131">Triton编程入门 by 董鑫 Nvidia Researcher​</a> 高质量</li>
<li><a href="https://zhuanlan.zhihu.com/p/613244988">谈谈对OpenAI Triton的一些理解 by 杨军 Nvidia compute arch</a> 高质量</li>
<li><a href="https://zhuanlan.zhihu.com/p/679232270">BBuf的CUDA笔记】十三，OpenAI Triton 入门笔记一</a> 高质量</li>
<li><a href="https://www.bilibili.com/video/BV11y3ne9Ec5/?share_source=copy_web&amp;vd_source=3157022a9ba8a59e9a2cac56650df970">Triton语言入门教程-智源人工智能研究院-20240602</a> 必看</li>
<li><a href="https://zhuanlan.zhihu.com/p/587304667">如何高效实现矩阵乘？万文长字带你从CUDA初学者的角度入门</a> 高质量</li>
</ul>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>