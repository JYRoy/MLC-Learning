# 08.Triton笔记八：基于Triton的项目调研

- [08.Triton笔记八：基于Triton的项目调研](#08triton笔记八基于triton的项目调研)
  - [Overview](#overview)
    - [FlagGems](#flaggems)
    - [LightLLM](#lightllm)
      - [源码结构](#源码结构)
      - [httpserver](#httpserver)
      - [router](#router)
      - [model](#model)
      - [detokensization](#detokensization)
  - [References](#references)

## Overview

目前社区中有很开源项目是基于Triton来实现的，尤其是大模型时代开始之后，本文是对这些项目的汇总解读

- FlagGems：
  - https://github.com/FlagOpen/FlagGems
  - 智源研究院
  - 基于Triton的大模型算子库
- LightLLM
  - 商汤
  - https://github.com/ModelTC/lightllm/tree/main
  - 基于Python的大模型推理和服务框架，使用Triton实现了在各大模型中公用的算子集合，例如attention、layernorm等

### FlagGems


### LightLLM

LightLLM是一个纯python项目，它集成了包括LLaMA、Baichuan、Yi等在内的国内外的开源语言模型，并构筑了一套标准化的python推理框架且实现了一套通用的优化方法。

```
BLOOM
LLaMA
LLaMA V2
StarCoder
Qwen-7b
ChatGLM2-6b
Baichuan-7b
Baichuan2-7b
Baichuan2-13b
Baichuan-13b
InternLM-7b
Yi-34b
Qwen-VL
Qwen-VL-Chat
Llava-7b
Llava-13b
Mixtral
Stablelm
MiniCPM
Phi-3
CohereForAI
```

LightLLM项目舍弃了以前常用的ONNX和TensorRT，使用PyTorch来进行显存管理和算子管理，使用Triton来进行kernel实现，使用huggingface来进行模型仓库资源的加载。

只要针对大模型常见的一些问题进行了优化：

- 显存碎片化，导致无法达到较高的吞吐量
- 请求调度效率低，请求的结束不可预知，长度动态变化，容易造成GPU利用率低
- kernel定制化难度高，传统的都是CUDA实现，想实现一个高效的定制化kernel难度高

根据官方文档介绍，LightLLM的核心feature为：

- 三进程架构：用于异步化处理tokensize和detokenize操作，避免耗时的cpu处理阻碍模型推理时的gpu调度执行和降低gpu利用率
- Token Attention：一种以token为粒度进行kv cache显存管理的特性
- Efficient Router：配合Token Attention用于精确的管理调度请求的合并推理

![LightLLM Arch.png](../.images/LightLLM%20Arch.png)

LightLLM的组件设计比较简单，整体分为四个部分：

1. httpserver：由fastapi控制的接收用户推理请求的主进程，同时负责tokensize
2. Router：组织调度模块，调用model和detoken来处理推理和输出，是一个单独的进程
3. detokensization：解码模块，独立进程
4. model：模型推理实现，通过rpc隔离开的单独进程

所谓的三进程是httpserver、router和detokensization三个进程，进程间通过pipe管道进行进程初始化状态的通信，通过zmq来进行主要通信。

#### 源码结构

```shell
|-- __init__.py
|-- common
|   |-- __init__.py
|   |-- basemodel
|   |-- build_utils.py
|   |-- infer_utils.py
|   |-- int8kv_mem_manager.py
|   |-- mem_manager.py
|   |-- mem_utils.py
|   |-- ppl_int4kv_mem_manager.py
|   |-- ppl_int8kv_mem_manager.py
|   `-- req_manager.py
|-- models
|   |-- __init__.py
|   |-- baichuan13b
|   |-- baichuan2_13b
|   |-- baichuan2_7b
|   |-- baichuan7b
|   |-- bloom
|   |-- chatglm2
|   |-- cohere
|   |-- gemma_2b
|   |-- internlm
|   |-- internlm2
|   |-- internlm2_wquant
|   |-- internlm_wquant
|   |-- internlm_xcomposer
|   |-- llama
|   |-- llama_awquant
|   |-- llama_quik
|   |-- llama_wquant
|   |-- llava
|   |-- minicpm
|   |-- mistral
|   |-- mixtral
|   |-- phi3
|   |-- qwen
|   |-- qwen2
|   |-- qwen2_wquant
|   |-- qwen_vl
|   |-- qwen_wquant
|   |-- stablelm
|   |-- starcoder
|   |-- starcoder2
|   |-- starcoder_wquant
|   `-- yi
|-- server
|   |-- __init__.py
|   |-- api_lightllm.py
|   |-- api_models.py
|   |-- api_server.py
|   |-- api_tgi.py
|   |-- build_prompt.py
|   |-- detokenization
|   |-- embed_cache
|   |-- health_monitor
|   |-- httpserver
|   |-- io_struct.py
|   |-- metrics
|   |-- multimodal_params.py
|   |-- req_id_generator.py
|   |-- router
|   |-- sampling_params.py
|   |-- tokenizer.py
|   `-- visualserver
`-- utils
    |-- __init__.py
    |-- graceful_utils.py
    |-- health_check.py
    |-- infer_utils.py
    |-- log_utils.py
    |-- net_utils.py
    |-- petrel_helper.py
    `-- start_utils.py
```

common中是模型的layer和kernel的公共实现

```shell
|-- __init__.py
|-- basemodel
|   |-- __init__.py
|   |-- basemodel.py
|   |-- cuda_kernel
|   |   |-- __init__.py
|   |   |-- fast_llm_wquant.py
|   |   |-- lmdeploy_wquant.py
|   |   |-- ppl_awquant.py
|   |   `-- ppl_wquant.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   |-- base_layer_infer.py
|   |   |-- post_layer_infer.py
|   |   |-- pre_layer_infer.py
|   |   |-- template
|   |   |   |-- __init__.py
|   |   |   |-- post_layer_infer_template.py
|   |   |   |-- pre_layer_infer_template.py
|   |   |   |-- transformer_layer_infer_cohere_template.py
|   |   |   |-- transformer_layer_infer_template.py
|   |   |   |-- transformer_layer_infer_template_awquant.py
|   |   |   `-- transformer_layer_infer_template_wquant.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- base_layer_weight.py
|   |   |-- hf_load_utils.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   |-- splitfuse_infer_struct.py
|   `-- triton_kernel
|       |-- __init__.py
|       |-- apply_penalty.py
|       |-- copy_kv_index_to_req.py
|       |-- dequantize_gemm_int4.py
|       |-- dequantize_gemm_int8.py
|       |-- destindex_copy_kv.py
|       |-- multimodal_emb.py
|       |-- quantize_gemm_int8.py
|       `-- splitfuse_copy_kv_index_to_req.py
|-- build_utils.py
|-- infer_utils.py
|-- int8kv_mem_manager.py
|-- mem_manager.py
|-- mem_utils.py
|-- ppl_int4kv_mem_manager.py
|-- ppl_int8kv_mem_manager.py
`-- req_manager.py
```

models中是具体的每一个模型的实现

- layer_infer：模型前向的实现，一般包含三个py实现对应了预测的三个计算阶段
  - pre_layer_infer.py：主要包含两个计算（1）embedding（2）layer norm
  - transformer_layer_infer.py：transformer layer的计算实现，包括attention、ffn、kv cache
  - post_layer_infer.py：输出层的预测实现
- layer_weights：加载基于huggingface上的模型权重的具体实现

```shell
|-- __init__.py
|-- baichuan13b
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- baichuan2_13b
|   |-- __init__.py
|   `-- model.py
|-- baichuan2_7b
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- pre_and_post_layer_weight.py
|   `-- model.py
|-- baichuan7b
|   |-- __init__.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- bloom
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   |-- post_layer_infer.py
|   |   |-- pre_layer_infer.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- hf_load_utils.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   |-- model.py
|   `-- triton_kernel
|       |-- __init__.py
|       |-- context_flashattention_nopad.py
|       |-- layernorm.py
|       |-- token_attention_nopad_att1.py
|       |-- token_attention_nopad_reduceV.py
|       |-- token_attention_nopad_softmax.py
|       `-- token_flashattention_nopad.py
|-- chatglm2
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   |-- model.py
|   `-- triton_kernel
|       |-- __init__.py
|       `-- rotary_emb.py
|-- cohere
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   |-- post_layer_infer.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   |-- model.py
|   |-- splitfuse_infer_struct.py
|   `-- triton_kernels
|       |-- __init__.py
|       |-- layernorm.py
|       `-- rotary_emb.py
|-- gemma_2b
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   |-- pre_layer_infer.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   |-- model.py
|   `-- triton_kernel
|       |-- __init__.py
|       `-- gelu_and_mul.py
|-- internlm
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- internlm2
|   |-- __init__.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- internlm2_wquant
|   |-- __init__.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- internlm_wquant
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- internlm_xcomposer
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- internlm_visual.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- llama
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   |-- post_layer_infer.py
|   |   |-- pre_layer_infer.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- ds_load_utils.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   |-- model.py
|   |-- splitfuse_infer_struct.py
|   |-- triton_kernel
|   |   |-- __init__.py
|   |   |-- context_flashattention_nopad.py
|   |   |-- flash_decoding.py
|   |   |-- flash_decoding_stage1.py
|   |   |-- flash_decoding_stage2.py
|   |   |-- gqa_decode_flashattention_nopad.py
|   |   |-- gqa_flash_decoding.py
|   |   |-- gqa_flash_decoding_stage1.py
|   |   |-- gqa_flash_decoding_stage2.py
|   |   |-- ppl_fp16_flash_decoding.py
|   |   |-- ppl_int4kv_copy_kv.py
|   |   |-- ppl_int4kv_flash_decoding.py
|   |   |-- ppl_int8kv_flash_decoding.py
|   |   |-- ppl_quant_copy_kv.py
|   |   |-- rmsnorm.py
|   |   |-- rotary_emb.py
|   |   |-- silu_and_mul.py
|   |   |-- splitfuse_context_flashattention_nopad.py
|   |   |-- token_attention_nopad_att1.py
|   |   |-- token_attention_nopad_reduceV.py
|   |   |-- token_attention_nopad_softmax.py
|   |   `-- token_attention_softmax_and_reducev.py
|   `-- yarn_rotary_utils.py
|-- llama_awquant
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- llama_quik
|   |-- __init__.py
|   |-- cuda_kernel
|   |   |-- __init__.py
|   |   `-- quik_awquant.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- qlinear.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- llama_wquant
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- llava
|   |-- __init__.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- pre_and_post_layer_weight.py
|   |-- llava_visual.py
|   `-- model.py
|-- minicpm
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- mistral
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- model.py
|   `-- triton_kernel
|       |-- __init__.py
|       |-- context_flashattention_nopad.py
|       |-- init_att_sliding_window_info.py
|       |-- token_attention_nopad_att1.py
|       |-- token_attention_nopad_reduceV.py
|       `-- token_attention_softmax_and_reducev.py
|-- mixtral
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- phi3
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   |-- model.py
|   `-- triton_kernel
|       |-- __init__.py
|       |-- context_flashattention_nopad.py
|       |-- destindex_copy_kv.py
|       |-- flash_decoding.py
|       |-- flash_decoding_stage1.py
|       |-- flash_decoding_stage2.py
|       `-- rotary_emb.py
|-- qwen
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- qwen2
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- qwen2_wquant
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- qwen_vl
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- pre_layer_infer.py
|   |-- model.py
|   `-- qwen_visual.py
|-- qwen_wquant
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- stablelm
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- starcoder
|   |-- __init__.py
|   |-- infer_struct.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   |-- pre_layer_infer.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- starcoder2
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   |-- pre_and_post_layer_weight.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
|-- starcoder_wquant
|   |-- __init__.py
|   |-- layer_infer
|   |   |-- __init__.py
|   |   `-- transformer_layer_infer.py
|   |-- layer_weights
|   |   |-- __init__.py
|   |   `-- transformer_layer_weight.py
|   `-- model.py
`-- yi
    |-- __init__.py
    |-- layer_weights
    |   |-- __init__.py
    |   `-- transformer_layer_weight.py
    `-- model.py
```

server中是LightLLM另一个重要部分的实现：httpserver和router

router的主要作用是调度模块，接收请求、组装batch后调用模型，将模型的输出结果给到detokenizer。

```shell
|-- __init__.py
|-- api_lightllm.py
|-- api_models.py
|-- api_server.py
|-- api_tgi.py
|-- build_prompt.py
|-- detokenization
|   |-- __init__.py
|   |-- decode.py
|   `-- manager.py
|-- embed_cache
|   |-- __init__.py
|   |-- impl
|   |   |-- __init__.py
|   |   `-- naive_memory_cache.py
|   |-- interface.py
|   |-- manager.py
|   `-- utils.py
|-- health_monitor
|   |-- __init__.py
|   `-- manager.py
|-- httpserver
|   |-- __init__.py
|   `-- manager.py
|-- io_struct.py
|-- metrics
|   |-- __init__.py
|   |-- manager.py
|   `-- metrics.py
|-- multimodal_params.py
|-- req_id_generator.py
|-- router
|   |-- __init__.py
|   |-- dynamic_prompt
|   |   |-- __init__.py
|   |   |-- radix_cache.py
|   |   `-- shared_arr.py
|   |-- manager.py
|   |-- model_infer
|   |   |-- __init__.py
|   |   |-- infer_batch.py
|   |   |-- mode_backend
|   |   |   |-- __init__.py
|   |   |   |-- base_backend.py
|   |   |   |-- beamsearch
|   |   |   |   |-- __init__.py
|   |   |   |   |-- impl.py
|   |   |   |   |-- post_process.py
|   |   |   |   `-- pre_process.py
|   |   |   |-- continues_batch
|   |   |   |   |-- __init__.py
|   |   |   |   |-- impl.py
|   |   |   |   |-- impl_for_return_all_prompt_logprobs.py
|   |   |   |   |-- post_process.py
|   |   |   |   `-- pre_process.py
|   |   |   |-- diverse_backend
|   |   |   |   |-- __init__.py
|   |   |   |   |-- impl.py
|   |   |   |   `-- post_process.py
|   |   |   `-- splitfuse
|   |   |       |-- __init__.py
|   |   |       |-- impl.py
|   |   |       `-- pre_process.py
|   |   `-- model_rpc.py
|   |-- pause_strategy.py
|   |-- req_queue
|   |   |-- __init__.py
|   |   |-- base_queue.py
|   |   |-- continues_batch
|   |   |   |-- __init__.py
|   |   |   |-- beam_impl.py
|   |   |   `-- impl.py
|   |   `-- splitfuse
|   |       |-- __init__.py
|   |       `-- impl.py
|   |-- stats.py
|   `-- token_load.py
|-- sampling_params.py
|-- tokenizer.py
`-- visualserver
    |-- __init__.py
    |-- manager.py
    `-- model_infer
        |-- __init__.py
        `-- model_rpc.py
```

#### httpserver

#### router

#### model

#### detokensization

## References

- [lightllm代码解读——之模型推理](https://zhuanlan.zhihu.com/p/666731524)


