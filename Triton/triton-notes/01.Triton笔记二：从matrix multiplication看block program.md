# Triton笔记二

- [Triton笔记二](#triton笔记二)
  - [Motivations](#motivations)
  - [Compute Kernel](#compute-kernel)
    - [Pointer Arithmetic](#pointer-arithmetic)
    - [L2 Cache Optimizations](#l2-cache-optimizations)
  - [实现](#实现)
    - [函数定义](#函数定义)
    - [Program 概念](#program-概念)
    - [Block 概念](#block-概念)
  - [References](#references)


## Motivations

传统的情况下，我们开发应用会选择使用厂商提供的计算库中的矩阵乘计算，例如cublas库，但是这种类型的库通常都是不开源的，对于现在更加多样的深度学习场景，我们很难去二次开发它。

相比之下，Triton的优势就非常的明显了，我们可以轻松的使用它来开发一些fused kernel，最典型的就是把activation和matrix multiplication结合起来。

对于MM的优化，其实大概的思路都差不多，因为总的计算量一定是不变的，所以能做的事情就是尽可能地使用shared memory，提高cache hit rate。

cache hit rate 理解为shared memory(L1 Cache)每次要到global memory找需要的数据时，会先去L2 Cache看是否存在，如果有就不用再去global memory了，有的概率越高，意味着cache hit rate越高。

所以我们希望尽可能的利用SRAM，但是因为它的空间比较小，所以基本原则是：每次往SRAM移动的数据，都要尽可能的被利用，避免来来回回搬迁。

## Compute Kernel

首先通过伪代码来看Triton中的(M, K) * (K, N)的矩阵乘的blocked算法。

```python
for m in range(0, M, BLOCK_SIZE_M):
    for n in range(0, N, BLOCK_SIZE_N):
        acc = zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=float32)
        for k in range(0, K, BLOCK_SIZE_K):
            a = A[m : m+BLOCK_SIZE_M, k : k+BLOCK_SIZE_K]
            b = B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]
            acc += dot(a, b)
        C[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N] = acc
```

其中主要的点在于，最内层的循环中需要从A、B矩阵中读出block块。因此，在这里需要引入multi-dimensional pointer运算。

### Pointer Arithmetic

对于行主序的2D矩阵x，想要通过指针来访问对应下标中的元素，公式为：

```python
X[i, j] = X_ptr + i * stride_xi + j * stride_xj
```

因此，如果要访问一个block的元素，采用类似的

```python
&A[m : m+BLOCK_SIZE_M, k:k+BLOCK_SIZE_K] =  a_ptr + (m : m+BLOCK_SIZE_M)[:, None]*A.stride(0) + (k : k+BLOCK_SIZE_K)[None, :]*A.stride(1);
&B[k : k+BLOCK_SIZE_K, n:n+BLOCK_SIZE_N] =  b_ptr + (k : k+BLOCK_SIZE_K)[:, None]*B.stride(0) + (n : n+BLOCK_SIZE_N)[None, :]*B.stride(1);
```

接下来就是Triton的实现，这里要注意的是Triton中M、N必须要是BLOCK_SIZE_M和BLOCK_SIZE_N的整数倍，如果不是的话，则需要一些空值来填充。

```python
offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
offs_k = tl.arange(0, BLOCK_SIZE_K)
a_ptrs = a_ptr + (offs_am[:, None]*stride_am + offs_k [None, :]*stride_ak)
b_ptrs = b_ptr + (offs_k [:, None]*stride_bk + offs_bn[None, :]*stride_bn)
a_ptrs += BLOCK_SIZE_K * stride_ak;
b_ptrs += BLOCK_SIZE_K * stride_bk;
```

### L2 Cache Optimizations

每一个program可以计算得到C中的一个[BLOCK_SIZE_M, BLOCK_SIZE_N]的block。

为了保证L2 Cache的命中率，这些block的顺序非常重要。

如果采用传统的行主序的形式（也就是从左到右，从上到下，一个一个block的按顺序计算），triton实现如下：

```python
@triton.jit
def matmul(A, B, C, M, N, K, stride_am, stride_ak, 
            stride_bk, stride_bn, stride_cm, stride_cn,
            **META):
    # extract metaparameters
    BLOCK_M, GROUP_M = META['BLOCK_M'], META['GROUP_M']
    BLOCK_N = META['BLOCK_N']
    BLOCK_K = META['BLOCK_K']
    # programs are grouped together to improve L2 hit rate
    _pid_m = tl.program_id(0)
    _pid_n = tl.program_id(1)
    pid_m = _pid_m // GROUP_M
    pid_n = (_pid_n * GROUP_M) + (_pid_m % GROUP_M)
    # rm (resp. rn) denotes a range of indices
    # for rows (resp. col) of C
    rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
    # rk denotes a range of indices for columns 
    # (resp. rows) of A (resp. B)
    rk = tl.arange(0, BLOCK_K)
    # the memory addresses of elements in the first block of
    # A and B can be computed using numpy-style broadcasting
    A = A + (rm[:, None] * stride_am + rk[None, :] * stride_ak)
    B = B + (rk [:, None] * stride_bk  + rn[None, :] * stride_bn)
    # initialize and iteratively update accumulator
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)
    for k in range(K, 0, -BLOCK_K):
        a = tl.load(A)
        b = tl.load(B)
        # block level matrix multiplication
        acc += tl.dot(a, b)
        # increment pointers so that the next blocks of A and B
        # are loaded during the next iteration
        A += BLOCK_K * stride_ak
        B += BLOCK_K * stride_bk
    # fuse leaky ReLU if desired
    # acc = tl.where(acc >= 0, acc, alpha * acc)
    # write back result
    C = C + (rm[:, None] * stride_cm + rn[None, :] * stride_cn)
    mask = (rm[:, None] < M) & (rn[None, :] < N)
    tl.store(C, acc, mask=mask)
```

一种可能的解决方案是按照促进数据重用的顺序启动block。triton可以通过在切换到下一列之前的super-grouping block来完成：

```python
# Program ID
pid = tl.program_id(axis=0)
# Number of program ids along the M axis
num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
# Number of programs ids along the N axis
num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
# Number of programs in group
num_pid_in_group = GROUP_SIZE_M * num_pid_n
# Id of the group this program is in
group_id = pid // num_pid_in_group
# Row-id of the first program in the group
first_pid_m = group_id * GROUP_SIZE_M
# If `num_pid_m` isn't divisible by `GROUP_SIZE_M`, the last group is smaller
group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)
# *Within groups*, programs are ordered in a column-major order
# Row-id of the program in the *launch grid*
pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)
# Col-id of the program in the *launch grid*
pid_n = (pid % num_pid_in_group) // group_size_m
```

这样看代码还是很抽象，但是可视化来看，就非常的清楚了，下面这种grouped ordering的方式，可以尽可能的提高cache hit rate，如果对于计算相同量级的C tile，需要加载的block更少，因此对于默认将数据加载到L2 Cache区域的GPU来说，这种方式更加的友好

1. row-major ordering：读入90个block，写9个block
2. grouped ordering：读入54个block，写9个block

![grouped_vs_row_major_ordering.png](../.images/grouped_vs_row_major_ordering.png)


实现上，我们采用对A的黄色区域行方向滚动，B的黄色区域列方向滚动，在C的黄色区域上不断的累加。

滚动计算过程中的更小的区域被称为tile，它会被加载到shared memory中（片上的）。也就是说A、B tile每次窗口滑动都是重新load到shared memory的，计算时再被加载到register上，而C tile一直在register中。如果所有的黄色区域，都能够在L2 Cache上存储下来，shared memory再次加载数据时，就不用从片外内存上去搬了，而是直接L2 Cache中就可以命中。

## 实现

### 函数定义

```python
@triton.jit
def matmul_kernel(
    # Pointers to matrices
    a_ptr,
    b_ptr,
    c_ptr,
    # Matrix dimensions
    M,
    N,
    K,
    # The stride variables represent how much to increase the ptr by when moving by 1
    # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`
    # by to get the element one row down (A has M rows).
    stride_am,
    stride_ak,  #
    stride_bk,
    stride_bn,  #
    stride_cm,
    stride_cn,
    # Meta-parameters
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,  #
    GROUP_SIZE_M: tl.constexpr,  #
    ACTIVATION: tl.constexpr,  #
)
```

1. `a_ptr`、`b_ptr`、`c_ptr`：tensor的指针，第一个元素的地址；
2. strides：和我们在torch中看到的stride是同一个概念，strid0对应0维+1需要的stride，stride1对应1维+1需要的stride，如果shape是一个(3,4)的tensor，那么它的stride是(4,1)；
3. Meta-parameters：剩下的tl.constexpr都是超参数l，在triton中超参数通过triton.Config和triton.autotune来设置；

### Program 概念

```python
pid = tl.program_id(axis=0)
```

这是在vector add用例中就已经看过的内容。在kernel中，写成只处理C的一部分输出的形式，但是执行完kernel后可以得到完成的C的原因，就是program在发挥它的作用。

program其实可以理解成循环，program_id理解成循环的index。

axis理解为嵌套的循环中有第几层循环，axis=0意味着只有一层循环，axis=1意味着有两层嵌套的循环，以此类推。

这个program在什么时候决定它到底有几层呢？其实不是在axis这里，这里可以理解为取出index。真正的设置循环的层数的地方在host代码中调用kernel的位置。

也就是这里的grid，它被定义为了一个lambda函数，它的值和输入x的M、N维度以及BLOCK_SIZE有关系，是一个一维值。能够和kernel内的axis=0对应上，都是一层的。

```python
grid = lambda META: (
    triton.cdiv(M, META["BLOCK_SIZE_M"]) * triton.cdiv(N, META["BLOCK_SIZE_N"]),
)
matmul_kernel[grid](
    a,
    b,
    c,  #
    M,
    N,
    K,  #
    a.stride(0),
    a.stride(1),  #
    b.stride(0),
    b.stride(1),  #
    c.stride(0),
    c.stride(1),  #
    ACTIVATION=activation,  #
)
```

### Block 概念

Block的概念，就是建立在program基础之上。

前面说了program理解为循环，每一个index对应了输出C矩阵中的一部分，这一部分就是我们说的block，block的大小是${BLOCK\_SIZE\_M} \times {BLOCK\_SIZE\_N}$，则循环的次数就是$\frac{M}{BLOCK\_SIZE\_M} \times \frac{N}{BLOCK\_SIZE\_N}$。

也就是说，完成$A\times B=C$，A的大小是$M \times K$，B的大小是$K \times N$，的运算，我们需要计算$\frac{M}{BLOCK\_SIZE\_M} \times \frac{N}{BLOCK\_SIZE\_N}$个block的内容。对于上面的图，grid=81。

所以，从block的角度，就是上面的super grouped ordering：先计算9个blocks，组合成一个大的super block，在进行下一个super block。

它的好处就是：

1. 同样都是计算9个block，读入的block更少
2. cache hit rate更高

对于输出C，它需要计算0到80的81个block。当program在axis=0维度上递增时，我们期望形成一下的代码逻辑： (pid_m, pid_n) 是黄色小块的坐标, 

```c++
for pid in range(81):
    pid --> (pid_m, pid_n)
```

对应到triton中的实现，我们要做的就是把pid转换为pid_m和pid_n

```python
num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
num_pid_in_group = GROUP_SIZE_M * num_pid_n
group_id = pid // num_pid_in_group
first_pid_m = group_id * GROUP_SIZE_M
group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)
pid_m = first_pid_m + (pid % group_size_m)
pid_n = (pid % num_pid_in_group) // group_size_m
```

- num_pid_m和num_pd_n：C矩阵长宽两个维度各组有多少的block
- num_pid_in_group：下图中红框部分的block数，高GROUP_SIZE_M，宽num_pid_n。对应一个红框内的block，它们会依次计算
  - ![grouped ordering num_pid_in_group.png](../.images/grouped%20ordering%20num_pid_in_group.png)
- group_id：红色框的id，当前pid在第几个框里
- first_pid_m：当前group在m维度上的第一个pid是多少
- group_id：因为最后一个group可能不满，所以需要获取当前pid的实际group size m
- pid_m和pid_n：是我们最后想要的值，当前pid（当前循环）在第几个block上
  - pid_m一定是小于first_pid_m + first_pid_m的

前面还是从高层的角度看block和super group。下面深入到一个block中，也就是triton kernel实现的角度。

![one block computation.png](../.images/one%20block%20computation.png)

A中第一行的9个block和B中第一列的9个block逐个相乘，放入accumulator累加器中，9个block计算完，也就得到了C中的第一个block。

这个过程意味着我们还要关注到A和B中的9个block，每个block有多少个元素，每个元素的指针地址是多少哦

```python
# ----------------------------------------------------------
# Create pointers for the first blocks of A and B.
# We will advance this pointer as we move in the K direction
# and accumulate
# `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers
# `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers
# See above `Pointer Arithmetics` section for details
offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
offs_k = tl.arange(0, BLOCK_SIZE_K)
a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)
b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)
```

以第一个block为例：

- a_ptr：A矩阵的第一个元素的地址
- b_ptr: B矩阵的第一个元素的地址
- offs_am：A矩阵9个block中的第一个block中每个元素在整个A矩阵中的行坐标
- offs_bn：B矩阵9个block中的第一个block中每个元素在整个B矩阵中的列坐标
- offs_k：A矩阵的列坐标，B矩阵的行坐标

有了行列坐标之后，和stride相乘，即可以得到每个元素的坐标a_ptr和b_ptrs

有了具体的坐标之后，进行乘加运算

```python
# -----------------------------------------------------------
# Iterate to compute a block of the C matrix.
# We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block
# of fp32 values for higher accuracy.
# `accumulator` will be converted back to fp16 after the loop.
accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):
    # Load the next block of A and B, generate a mask by checking the K dimension.
    # If it is out of bounds, set it to 0.
    a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)
    b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)
    # We accumulate along the K dimension.
    accumulator += tl.dot(a, b)
    # Advance the ptrs to the next K block.
    a_ptrs += BLOCK_SIZE_K * stride_ak
    b_ptrs += BLOCK_SIZE_K * stride_bk
```

mask的作用是当K不能被BLOCK_SIZE_K整除时，到每一行最后一个block时，实际大小不足BLOCK_SIZE_K，需要使用mask遮蔽掉

```python
accumulator += tl.dot(a, b)
```

计算了一个block的值之后移动到下一个block的元素

```python
a_ptrs += BLOCK_SIZE_K * stride_ak
b_ptrs += BLOCK_SIZE_K * stride_bk
```

经过计算第一个C中的block后，写回到DRAM中，即完成了第一个block的全部操作

```python
# -----------------------------------------------------------
# Write back the block of the output matrix C with masks.
offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]
c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
tl.store(c_ptrs, c, mask=c_mask)
```

在上述的program基础上，叠加上program的并行化，81个block经过81个program计算后得到了完整的C矩阵。

## References

- [Triton tutorial matrix multiplication](https://triton-lang.org/main/getting-started/tutorials/03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py) 必看
- [Triton编程入门 by 董鑫​](https://www.zhihu.com/question/622685131) 高质量
